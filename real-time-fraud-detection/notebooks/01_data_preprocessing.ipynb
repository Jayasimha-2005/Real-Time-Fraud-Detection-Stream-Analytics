{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a11ef57",
   "metadata": {},
   "source": [
    "# Phase 1: Data Preparation & Baseline Model\\n\n",
    "\\n\n",
    "## Goals:\\n\n",
    "- Load and explore creditcard.csv dataset\\n\n",
    "- Analyze class imbalance\\n\n",
    "- Preprocess data\\n\n",
    "- Build baseline models (Logistic Regression, Random Forest)\\n\n",
    "- Evaluate baseline performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb2c06b",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c9ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\\n\n",
    "import pandas as pd\\n\n",
    "import matplotlib.pyplot as plt\\n\n",
    "import seaborn as sns\\n\n",
    "from sklearn.model_selection import train_test_split\\n\n",
    "from sklearn.preprocessing import StandardScaler\\n\n",
    "from sklearn.linear_model import LogisticRegression\\n\n",
    "from sklearn.ensemble import RandomForestClassifier\\n\n",
    "from sklearn.metrics import (\\n\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\\n\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\\n\n",
    ")\\n\n",
    "import warnings\\n\n",
    "warnings.filterwarnings('ignore')\\n\n",
    "\\n\n",
    "# Set style\\n\n",
    "sns.set_style('whitegrid')\\n\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\\n\n",
    "\\n\n",
    "print('All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354eaec2",
   "metadata": {},
   "source": [
    "## Step 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the creditcard.csv dataset\\n\n",
    "# Download from: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\\n\n",
    "\\n\n",
    "try:\\n\n",
    "    df = pd.read_csv('../../data/raw/creditcard.csv')\\n\n",
    "    print(f'Dataset loaded successfully!')\\n\n",
    "    print(f'Shape: {df.shape}')\\n\n",
    "    print(f'\\\\nColumns: {df.columns.tolist()}')\\n\n",
    "except FileNotFoundError:\\n\n",
    "    print('ERROR: creditcard.csv not found in data/raw/ folder')\\n\n",
    "    print('Please download from: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud')\\n\n",
    "    print('And place it in: data/raw/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb94bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\\n\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data info\\n\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\\n\n",
    "print('Missing Values:')\\n\n",
    "print(df.isnull().sum())\\n\n",
    "print(f'\\\\nTotal missing values: {df.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a70542",
   "metadata": {},
   "source": [
    "## Step 3: Analyze Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39096842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\\n\n",
    "class_counts = df['Class'].value_counts()\\n\n",
    "class_percentages = df['Class'].value_counts(normalize=True) * 100\\n\n",
    "\\n\n",
    "print('Class Distribution:')\\n\n",
    "print(f'Normal transactions (0): {class_counts[0]:,} ({class_percentages[0]:.2f}%)')\\n\n",
    "print(f'Fraud transactions (1): {class_counts[1]:,} ({class_percentages[1]:.2f}%)')\\n\n",
    "print(f'\\\\nImbalance Ratio: {class_counts[0] / class_counts[1]:.2f}:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\\n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n\n",
    "\\n\n",
    "# Count plot\\n\n",
    "sns.countplot(data=df, x='Class', ax=axes[0], palette=['#2ecc71', '#e74c3c'])\\n\n",
    "axes[0].set_title('Class Distribution (Count)', fontsize=14, fontweight='bold')\\n\n",
    "axes[0].set_xlabel('Class (0=Normal, 1=Fraud)', fontsize=12)\\n\n",
    "axes[0].set_ylabel('Count', fontsize=12)\\n\n",
    "\\n\n",
    "# Percentage plot\\n\n",
    "class_percentages.plot(kind='bar', ax=axes[1], color=['#2ecc71', '#e74c3c'])\\n\n",
    "axes[1].set_title('Class Distribution (Percentage)', fontsize=14, fontweight='bold')\\n\n",
    "axes[1].set_xlabel('Class (0=Normal, 1=Fraud)', fontsize=12)\\n\n",
    "axes[1].set_ylabel('Percentage (%)', fontsize=12)\\n\n",
    "axes[1].set_xticklabels(['Normal', 'Fraud'], rotation=0)\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6eac7",
   "metadata": {},
   "source": [
    "## Step 4: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8e816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\\n\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Amount distribution\\n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n\n",
    "\\n\n",
    "# Amount distribution by class\\n\n",
    "df[df['Class'] == 0]['Amount'].hist(bins=50, ax=axes[0], alpha=0.7, label='Normal', color='#2ecc71')\\n\n",
    "df[df['Class'] == 1]['Amount'].hist(bins=50, ax=axes[0], alpha=0.7, label='Fraud', color='#e74c3c')\\n\n",
    "axes[0].set_title('Transaction Amount Distribution', fontsize=14, fontweight='bold')\\n\n",
    "axes[0].set_xlabel('Amount', fontsize=12)\\n\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\\n\n",
    "axes[0].legend()\\n\n",
    "\\n\n",
    "# Boxplot\\n\n",
    "df.boxplot(column='Amount', by='Class', ax=axes[1], patch_artist=True)\\n\n",
    "axes[1].set_title('Transaction Amount by Class', fontsize=14, fontweight='bold')\\n\n",
    "axes[1].set_xlabel('Class (0=Normal, 1=Fraud)', fontsize=12)\\n\n",
    "axes[1].set_ylabel('Amount', fontsize=12)\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68832ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap (sample for visualization)\\n\n",
    "plt.figure(figsize=(12, 10))\\n\n",
    "correlation = df.corr()\\n\n",
    "sns.heatmap(correlation[['Class']].sort_values(by='Class', ascending=False).head(15), \\n\n",
    "            annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\\n\n",
    "plt.title('Top 15 Features Correlated with Fraud Class', fontsize=14, fontweight='bold')\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd2a775",
   "metadata": {},
   "source": [
    "## Step 5: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\\n\n",
    "X = df.drop('Class', axis=1)\\n\n",
    "y = df['Class']\\n\n",
    "\\n\n",
    "print(f'Features shape: {X.shape}')\\n\n",
    "print(f'Target shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Amount and Time\\n\n",
    "scaler = StandardScaler()\\n\n",
    "X['Amount'] = scaler.fit_transform(X['Amount'].values.reshape(-1, 1))\\n\n",
    "X['Time'] = scaler.fit_transform(X['Time'].values.reshape(-1, 1))\\n\n",
    "\\n\n",
    "print('Amount and Time normalized!')\\n\n",
    "print(f'\\\\nNormalized data sample:')\\n\n",
    "X[['Time', 'Amount']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0b4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\\n\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\n\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\\n\n",
    ")\\n\n",
    "\\n\n",
    "print(f'Training set: {X_train.shape}')\\n\n",
    "print(f'Test set: {X_test.shape}')\\n\n",
    "print(f'\\\\nTraining set class distribution:')\\n\n",
    "print(y_train.value_counts())\\n\n",
    "print(f'\\\\nTest set class distribution:')\\n\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data\\n\n",
    "import os\\n\n",
    "\\n\n",
    "os.makedirs('../../data/processed', exist_ok=True)\\n\n",
    "\\n\n",
    "X_train.to_csv('../../data/processed/X_train.csv', index=False)\\n\n",
    "X_test.to_csv('../../data/processed/X_test.csv', index=False)\\n\n",
    "y_train.to_csv('../../data/processed/y_train.csv', index=False)\\n\n",
    "y_test.to_csv('../../data/processed/y_test.csv', index=False)\\n\n",
    "\\n\n",
    "print('Preprocessed data saved to data/processed/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ad581",
   "metadata": {},
   "source": [
    "## Step 6: Baseline Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\\n\n",
    "print('Training Logistic Regression...')\\n\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\\n\n",
    "lr_model.fit(X_train, y_train)\\n\n",
    "\\n\n",
    "# Predictions\\n\n",
    "y_pred_lr = lr_model.predict(X_test)\\n\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test)[:, 1]\\n\n",
    "\\n\n",
    "print('\\\\nLogistic Regression trained successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2077b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Logistic Regression\\n\n",
    "print('=== LOGISTIC REGRESSION RESULTS ===')\\n\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}')\\n\n",
    "print(f'Precision: {precision_score(y_test, y_pred_lr):.4f}')\\n\n",
    "print(f'Recall: {recall_score(y_test, y_pred_lr):.4f}')\\n\n",
    "print(f'F1-Score: {f1_score(y_test, y_pred_lr):.4f}')\\n\n",
    "print(f'ROC-AUC: {roc_auc_score(y_test, y_pred_proba_lr):.4f}')\\n\n",
    "print('\\\\nClassification Report:')\\n\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Normal', 'Fraud']))\\n\n",
    "print('\\\\nConfusion Matrix:')\\n\n",
    "print(confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902b6e3",
   "metadata": {},
   "source": [
    "## Step 7: Baseline Model - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85600d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\\n\n",
    "print('Training Random Forest...')\\n\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, \\n\n",
    "                                   class_weight='balanced', n_jobs=-1)\\n\n",
    "rf_model.fit(X_train, y_train)\\n\n",
    "\\n\n",
    "# Predictions\\n\n",
    "y_pred_rf = rf_model.predict(X_test)\\n\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\\n\n",
    "\\n\n",
    "print('\\\\nRandom Forest trained successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c598311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Forest\\n\n",
    "print('=== RANDOM FOREST RESULTS ===')\\n\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}')\\n\n",
    "print(f'Precision: {precision_score(y_test, y_pred_rf):.4f}')\\n\n",
    "print(f'Recall: {recall_score(y_test, y_pred_rf):.4f}')\\n\n",
    "print(f'F1-Score: {f1_score(y_test, y_pred_rf):.4f}')\\n\n",
    "print(f'ROC-AUC: {roc_auc_score(y_test, y_pred_proba_rf):.4f}')\\n\n",
    "print('\\\\nClassification Report:')\\n\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Normal', 'Fraud']))\\n\n",
    "print('\\\\nConfusion Matrix:')\\n\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202e16ca",
   "metadata": {},
   "source": [
    "## Step 8: Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129fcf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models visually\\n\n",
    "models = ['Logistic Regression', 'Random Forest']\\n\n",
    "accuracy = [accuracy_score(y_test, y_pred_lr), accuracy_score(y_test, y_pred_rf)]\\n\n",
    "precision = [precision_score(y_test, y_pred_lr), precision_score(y_test, y_pred_rf)]\\n\n",
    "recall = [recall_score(y_test, y_pred_lr), recall_score(y_test, y_pred_rf)]\\n\n",
    "f1 = [f1_score(y_test, y_pred_lr), f1_score(y_test, y_pred_rf)]\\n\n",
    "\\n\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\\n\n",
    "\\n\n",
    "# Accuracy\\n\n",
    "axes[0, 0].bar(models, accuracy, color=['#3498db', '#e67e22'])\\n\n",
    "axes[0, 0].set_title('Accuracy Comparison', fontsize=12, fontweight='bold')\\n\n",
    "axes[0, 0].set_ylim([0, 1])\\n\n",
    "\\n\n",
    "# Precision\\n\n",
    "axes[0, 1].bar(models, precision, color=['#3498db', '#e67e22'])\\n\n",
    "axes[0, 1].set_title('Precision Comparison', fontsize=12, fontweight='bold')\\n\n",
    "axes[0, 1].set_ylim([0, 1])\\n\n",
    "\\n\n",
    "# Recall\\n\n",
    "axes[1, 0].bar(models, recall, color=['#3498db', '#e67e22'])\\n\n",
    "axes[1, 0].set_title('Recall Comparison', fontsize=12, fontweight='bold')\\n\n",
    "axes[1, 0].set_ylim([0, 1])\\n\n",
    "\\n\n",
    "# F1-Score\\n\n",
    "axes[1, 1].bar(models, f1, color=['#3498db', '#e67e22'])\\n\n",
    "axes[1, 1].set_title('F1-Score Comparison', fontsize=12, fontweight='bold')\\n\n",
    "axes[1, 1].set_ylim([0, 1])\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve comparison\\n\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\\n\n",
    "\\n\n",
    "# Plot ROC curves\\n\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_proba_lr)\\n\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\\n\n",
    "\\n\n",
    "ax.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_score(y_test, y_pred_proba_lr):.3f})', linewidth=2)\\n\n",
    "ax.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_score(y_test, y_pred_proba_rf):.3f})', linewidth=2)\\n\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\\n\n",
    "\\n\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\\n\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\\n\n",
    "ax.set_title('ROC Curve Comparison - Baseline Models', fontsize=14, fontweight='bold')\\n\n",
    "ax.legend(fontsize=10)\\n\n",
    "ax.grid(alpha=0.3)\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98385de",
   "metadata": {},
   "source": [
    "## Step 9: Save Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\\n\n",
    "\\n\n",
    "# Save models\\n\n",
    "os.makedirs('../../models/saved_models', exist_ok=True)\\n\n",
    "\\n\n",
    "joblib.dump(lr_model, '../../models/saved_models/logistic_regression.pkl')\\n\n",
    "joblib.dump(rf_model, '../../models/saved_models/random_forest.pkl')\\n\n",
    "\\n\n",
    "print('Baseline models saved successfully!')\\n\n",
    "print('- logistic_regression.pkl')\\n\n",
    "print('- random_forest.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b905efc6",
   "metadata": {},
   "source": [
    "## Phase 1 Summary\\n\n",
    "\\n\n",
    "### âœ… Completed:\\n\n",
    "1. Loaded creditcard.csv dataset\\n\n",
    "2. Analyzed class imbalance (~0.17% fraud)\\n\n",
    "3. Performed exploratory data analysis\\n\n",
    "4. Preprocessed and normalized data\\n\n",
    "5. Built baseline models (Logistic Regression & Random Forest)\\n\n",
    "6. Evaluated and compared baseline performance\\n\n",
    "7. Saved preprocessed data and models\\n\n",
    "\\n\n",
    "### ðŸ”¥ Key Findings:\\n\n",
    "- Dataset is highly imbalanced\\n\n",
    "- Baseline models provide initial benchmarks\\n\n",
    "- Ready for deep learning models in Phase 2\\n\n",
    "\\n\n",
    "### ðŸ“Š Next Steps:\\n\n",
    "- Move to notebook 02: LSTM Model\\n\n",
    "- Build sequential deep learning models\\n\n",
    "- Improve fraud detection performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
